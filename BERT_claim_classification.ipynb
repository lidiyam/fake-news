{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT claim classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66HX8a9_-kNu",
        "colab_type": "text"
      },
      "source": [
        "## Problem Overview\n",
        "The goal is to predict the truth ratings that human fact checkers would assign to each\n",
        "claim in the dataset based on some related articles and the metadata associated with each claim.\n",
        "\n",
        "## Data\n",
        "The dataset contains claims and the associated metadata from 9 fact checking\n",
        "websites. On those\n",
        "websites, professional fact checkers publish a truth rating for each claim with links to the related articles. The truth ratings provided were mapped to the labels:\n",
        "-  0 (false)\n",
        "-  1 (partly true) \n",
        "- 2 (true)\n",
        "\n",
        "## Approach\n",
        "\n",
        "In this notebook, I've implemented the following approach.\n",
        "\n",
        "First, the claim and the related articles are preprocessed by converting each\n",
        "sentence into a TF-IDF representation. The 5 sentences that have the highest cosine\n",
        "similarity with a claim are extracted and concatenated with the metadata. \n",
        "\n",
        "Then,\n",
        "Bi-directional Encoder Representations from Transformers (BERT) is fine-tuned\n",
        "based on these sentences and the metadata to predict the label of each claim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4t1E4M1QHTf",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yzyedk4PI-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c5664bc4-e378-4770-b0e8-27cc1bd29cb2"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urqYuJgUPaJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "14e5da8e-d46b-408f-9810-b7d56f480b77"
      },
      "source": [
        "!gdown --id 1Hxk35b28q85y2HrtE1V_We_WlcMaOd25"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hxk35b28q85y2HrtE1V_We_WlcMaOd25\n",
            "To: /content/leadersboard2019.zip\n",
            "195MB [00:01, 119MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw3SdQHegFNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e17d9729-9150-473f-9b13-7a8c1cb7b04a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  leadersboard2019.zip  sample_data  train_articles  train.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUWP5QAXgp6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0a98a71-fc06-41af-fdf6-b0e5785a8e6c"
      },
      "source": [
        "!unzip leadersboard2019.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  leadersboard2019.zip\n",
            "replace train.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cno2K8V8JfW-",
        "colab_type": "code",
        "outputId": "e2be1c7a-6439-4feb-fcb0-00658f5093fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6K7wmDlhWT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c7bd559-d293-41ae-954e-294c23fc13ca"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GGmm-EQi3Wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "05de5321-5a93-4eae-d688-8c295c70419e"
      },
      "source": [
        "def preprocess_articles():\n",
        "    # load metadata\n",
        "    with open(\"train.json\", 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "    n_claims = len(metadata)\n",
        "\n",
        "    # load related articles for each claim\n",
        "    relevant_sentences = []\n",
        "    for id in range(n_claims):\n",
        "  \n",
        "        if id % 500 == 0:\n",
        "            print(\"Claims preprocessed: \",id)\n",
        "        \n",
        "        # retrieve related articles\n",
        "        related_articles = metadata[id]['related_articles']\n",
        "        articles = \"\"\n",
        "        for article_id in related_articles:\n",
        "            filename = \"train_articles/\" + str(article_id) + \".txt\"\n",
        "            # concatenate related articles\n",
        "            with open(filename, 'r') as text_file:\n",
        "                text = text_file.read()\n",
        "                articles = articles + \"\\n\" + text\n",
        "\n",
        "        # split articles into sentences\n",
        "        sentences = sent_tokenize(articles)\n",
        "\n",
        "        # append claim to articles\n",
        "        sentences.append(metadata[id]['claim'])\n",
        "\n",
        "        # vectorize sentences based on tf-idf\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        X = vectorizer.fit_transform(sentences)\n",
        "    \n",
        "        # measure similarity between claim and each sentence\n",
        "        similarity =  X[-1,:] @ np.transpose(X[:-2,:])\n",
        "        similarity = similarity.todense()\n",
        "\n",
        "        # find top 5 sentences with greatest similarity\n",
        "        sorted_index = np.argsort(similarity)\n",
        "        top_sentences = []\n",
        "        for i in range(1,min(5,sorted_index.shape[1])+1):\n",
        "            top_sentences.append(sentences[sorted_index[0,-i]])\n",
        "        relevant_sentences.append(top_sentences)\n",
        "\n",
        "   \n",
        "    return metadata, relevant_sentences\n",
        "\n",
        "metadata, relevant_sentences = preprocess_articles()\n",
        "n_claims = len(metadata)\n",
        "print('Number of claims: {:,}\\n'.format(n_claims))\n",
        "print(\"Metadata of claim 0:\")\n",
        "print(metadata[0]['claim'])\n",
        "print(\"Relevant sentences of claim 0:\")\n",
        "print(relevant_sentences[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Claims preprocessed:  0\n",
            "Claims preprocessed:  500\n",
            "Claims preprocessed:  1000\n",
            "Claims preprocessed:  1500\n",
            "Claims preprocessed:  2000\n",
            "Claims preprocessed:  2500\n",
            "Claims preprocessed:  3000\n",
            "Claims preprocessed:  3500\n",
            "Claims preprocessed:  4000\n",
            "Claims preprocessed:  4500\n",
            "Claims preprocessed:  5000\n",
            "Claims preprocessed:  5500\n",
            "Claims preprocessed:  6000\n",
            "Claims preprocessed:  6500\n",
            "Claims preprocessed:  7000\n",
            "Claims preprocessed:  7500\n",
            "Claims preprocessed:  8000\n",
            "Claims preprocessed:  8500\n",
            "Claims preprocessed:  9000\n",
            "Claims preprocessed:  9500\n",
            "Claims preprocessed:  10000\n",
            "Claims preprocessed:  10500\n",
            "Claims preprocessed:  11000\n",
            "Claims preprocessed:  11500\n",
            "Claims preprocessed:  12000\n",
            "Claims preprocessed:  12500\n",
            "Claims preprocessed:  13000\n",
            "Claims preprocessed:  13500\n",
            "Claims preprocessed:  14000\n",
            "Claims preprocessed:  14500\n",
            "Claims preprocessed:  15000\n",
            "Claims preprocessed:  15500\n",
            "Number of claims: 15,555\n",
            "\n",
            "Metadata of claim 0:\n",
            "A line from George Orwell's novel 1984 predicts the power of smartphones.\n",
            "Relevant sentences of claim 0:\n",
            "['1984 by George Orwell\\n1984 is a dystopian novel by English author George Orwell published in 1949.', 'Theater Review: \\'1984\\'\\nEarly this year, sales of George Orwell\\'s novel \"1984\" spiked after the words \"alternative facts\" entered the lexicon.', 'It is truly frightening to see the parallels between George Orwell\\'s dystopian novel \"1984\" and the state of our union today.', '\\n1984: George Orwell predicted 2017 almost 70 years ago\\nApril, 1984.', 'The line is from one of the characters that works for the Government, otherwise known as Big Brother.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xivg8VwVhfHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "df = pd.DataFrame.from_dict(json_normalize(metadata), orient='columns')\n",
        "df[\"relevant_sentences\"] = np.asarray(relevant_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o5b9CT1hsOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "48933d28-a9c7-4203-8402-86cdfa1b24c2"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>claimant</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "      <th>related_articles</th>\n",
              "      <th>id</th>\n",
              "      <th>relevant_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12078</th>\n",
              "      <td>In early January 2019, all speed cameras on th...</td>\n",
              "      <td></td>\n",
              "      <td>2019-01-10</td>\n",
              "      <td>0</td>\n",
              "      <td>[105108, 133664, 133665, 148710]</td>\n",
              "      <td>13308</td>\n",
              "      <td>[\\nFrank Sinclair on Twitter: \"All cameras on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8439</th>\n",
              "      <td>A photograph depicts a sign on a unisex Kroger...</td>\n",
              "      <td></td>\n",
              "      <td>2016-03-31</td>\n",
              "      <td>2</td>\n",
              "      <td>[120047, 136261, 136617]</td>\n",
              "      <td>9308</td>\n",
              "      <td>[— Ramblin' Man (@RamblinManNC) March 29, 2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13276</th>\n",
              "      <td>“No letter [from Yanukovych in 2014] was offic...</td>\n",
              "      <td>Dmitry Peskov</td>\n",
              "      <td>2017-03-20</td>\n",
              "      <td>1</td>\n",
              "      <td>[134194, 133030, 151420, 124306, 111981, 122623]</td>\n",
              "      <td>14628</td>\n",
              "      <td>[\"No letter was officially submitted to the Ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11793</th>\n",
              "      <td>American liberals are debating the merits of \"...</td>\n",
              "      <td></td>\n",
              "      <td>2018-10-12</td>\n",
              "      <td>1</td>\n",
              "      <td>[107062, 109289, 109733, 126062, 126322, 12645...</td>\n",
              "      <td>12988</td>\n",
              "      <td>[Adoption as an alternative to after-birth abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2217</th>\n",
              "      <td>Tiger Woods named his restaurant “The Woods Ju...</td>\n",
              "      <td></td>\n",
              "      <td>2015-03-13</td>\n",
              "      <td>0</td>\n",
              "      <td>[119090, 119091]</td>\n",
              "      <td>2447</td>\n",
              "      <td>[“Tiger owns his own name and always had., The...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim  ...                                 relevant_sentences\n",
              "12078  In early January 2019, all speed cameras on th...  ...  [\\nFrank Sinclair on Twitter: \"All cameras on ...\n",
              "8439   A photograph depicts a sign on a unisex Kroger...  ...  [— Ramblin' Man (@RamblinManNC) March 29, 2016...\n",
              "13276  “No letter [from Yanukovych in 2014] was offic...  ...  [\"No letter was officially submitted to the Ru...\n",
              "11793  American liberals are debating the merits of \"...  ...  [Adoption as an alternative to after-birth abo...\n",
              "2217   Tiger Woods named his restaurant “The Woods Ju...  ...  [“Tiger owns his own name and always had., The...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeKs67Qkk6XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "46efabff-a9c1-4954-9f6d-1d6f7f0e1cf6"
      },
      "source": [
        "df.loc[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "claim                 A line from George Orwell's novel 1984 predict...\n",
              "claimant                                                               \n",
              "date                                                         2017-07-17\n",
              "label                                                                 0\n",
              "related_articles                       [122094, 122580, 130685, 134765]\n",
              "id                                                                    0\n",
              "relevant_sentences    [1984 by George Orwell\\n1984 is a dystopian no...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDSNpcWBFEAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "e9a2e283-3025-400b-9b28-cd56ba4df011"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpaRAvWwNWhx",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrzgdEPahzmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-evhqmvh3Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_input_ids = []\n",
        "all_attention_masks = []\n",
        "all_token_type_ids = []\n",
        "all_labels = []\n",
        "all_features = []\n",
        "data_len = df.shape[0]\n",
        "for i in range(data_len):\n",
        "  claim = df.loc[i].claim\n",
        "  text = \" \".join(df.loc[i].relevant_sentences)\n",
        "  label = df.loc[i].label\n",
        "  \n",
        "  features = tokenizer.encode_plus(claim, text, add_special_tokens=True, max_length=512, pad_to_max_length=True, return_tensors='pt')\n",
        "  all_features.append(features)\n",
        "  all_input_ids.append(features['input_ids'].flatten())\n",
        "  all_attention_masks.append(features['attention_mask'].flatten())\n",
        "  all_token_type_ids.append(features['token_type_ids'].flatten())\n",
        "  all_labels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0uAqNOeNZ4c",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsqOjdKyzz_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0f7d1fac-2215-45c7-f1ea-db2a82e3d1fe"
      },
      "source": [
        "SPLIT = 10000\n",
        "train_input_ids_tensor = torch.stack(all_input_ids[:SPLIT]).long()\n",
        "train_attention_masks = torch.stack(all_attention_masks[:SPLIT]).long()\n",
        "train_token_type_ids = torch.stack(all_token_type_ids[:SPLIT]).long()\n",
        "train_labels = torch.tensor(torch.tensor(all_labels[:SPLIT]).reshape(-1,1), dtype=torch.long)\n",
        "\n",
        "test_input_ids_tensor = torch.stack(all_input_ids[SPLIT:]).long()\n",
        "test_attention_masks = torch.stack(all_attention_masks[SPLIT:]).long()\n",
        "test_token_type_ids = torch.stack(all_token_type_ids[SPLIT:]).long()\n",
        "test_labels = torch.tensor(torch.tensor(all_labels[SPLIT:]).reshape(-1,1), dtype=torch.long).reshape(-1, 1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA_a7IQQyl6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 12\n",
        "EPOCHS = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLcUzwnepk6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_input_ids_tensor, train_attention_masks, train_token_type_ids, train_labels)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_input_ids_tensor, test_attention_masks, test_token_type_ids, test_labels)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmApMbylNh__",
        "colab_type": "text"
      },
      "source": [
        "## Fine-Tune BERT For Sequence Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfan_ixlospe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc729f71-e453-4326-873b-eba89473677d"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI0TFUcfwKT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b742ddd-ddd3-4fe4-8240-1b9b27511b39"
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvnz7gTEvTVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef26fd97-15ff-407c-e3b8-30078b8ca27f"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKHwJi5ywQUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c65502d7-6773-47a0-d422-c1f1ea0358c9"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'439.071232M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY1W3qQtwVEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=3e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBkAJKuPByIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FQPW3d4Nw1w",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmMXCb3cwVz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a3c3af1c-0bfc-40f4-a3fb-b03d3642154d"
      },
      "source": [
        "loss_values = []\n",
        "for epoch_num in range(EPOCHS):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_num + 1, EPOCHS))\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        input_ids, attn_masks, token_type_ids, labels = tuple(t.to(device) for t in batch_data)\n",
        "        model.zero_grad()  \n",
        "        outputs = model(input_ids, \n",
        "                    token_type_ids=token_type_ids, \n",
        "                    attention_mask=attn_masks,\n",
        "                    labels=labels)\n",
        "        loss = outputs[0]\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "    avg_train_loss = train_loss / len(train_dataloader)                \n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.91\n",
            "Training epcoh took: 0:18:13\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.84\n",
            "Training epcoh took: 0:18:22\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.79\n",
            "Training epcoh took: 0:18:22\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.74\n",
            "Training epcoh took: 0:18:21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZCwhhCVxYM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "b94817f3-32c7-4723-a021-cdd277e8c1bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(loss_values, 'b-o')\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvoAAAGaCAYAAAB+A+cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWanj1WcNzz0",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfJskULX83fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction on test set\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        b_input_ids, b_attn_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids, \n",
        "                      attention_mask=b_attn_masks)\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "        # The predictions for this batch are a 3-column ndarray (one column for \"0\",\n",
        "        # one column for \"1\", one column for \"2\"). Pick the label with the highest value and turn this\n",
        "        # in to a list of 0s and 1s.\n",
        "        pred_labels_i = np.argmax(logits, axis=1).flatten()\n",
        "        bert_predicted.extend(pred_labels_i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGXAxvSf9ANn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2cd923d2-16c9-4cab-fdb6-fc5769787500"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, bert_predicted))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.70      0.69      2621\n",
            "           1       0.60      0.73      0.66      2355\n",
            "           2       0.30      0.01      0.02       579\n",
            "\n",
            "    accuracy                           0.64      5555\n",
            "   macro avg       0.53      0.48      0.46      5555\n",
            "weighted avg       0.61      0.64      0.61      5555\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}